{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from preprocessing.preprocess import DataPreprocessor\n",
    "from preprocessing.transformations import fix_label_type\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################\n",
    "## Load train dataset\n",
    "\n",
    "df_train = pd.read_csv('Data/virus_hw5.csv')\n",
    "X_ids = df_train['PatientID']\n",
    "X_train, y_train = df_train.drop(labels=['TestResultsCode'], axis=1), df_train[['TestResultsCode']]\n",
    "y_train = fix_label_type(y_train)\n",
    "\n",
    "X_train = X_train[['DisciplineScore', 'TimeOnSocialActivities', 'AgeGroup', 'StepsPerYear', 'pcrResult4', 'pcrResult1',\n",
    "                   'pcrResult12', 'pcrResult5', 'pcrResult16', 'pcrResult14', 'SyndromeClass']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = DataPreprocessor().fit(X_train, y_train)\n",
    "X_train = preprocessor.transform(X_train)\n",
    "X_val = preprocessor.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1800 entries, 0 to 1799\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   DisciplineScore         1800 non-null   float64\n",
      " 1   TimeOnSocialActivities  1800 non-null   float64\n",
      " 2   AgeGroup                1800 non-null   float64\n",
      " 3   StepsPerYear            1800 non-null   float64\n",
      " 4   pcrResult4              1800 non-null   float64\n",
      " 5   pcrResult1              1800 non-null   float64\n",
      " 6   pcrResult12             1800 non-null   float64\n",
      " 7   pcrResult5              1800 non-null   float64\n",
      " 8   pcrResult16             1800 non-null   float64\n",
      " 9   pcrResult14             1800 non-null   float64\n",
      " 10  SyndromeClass_1.0       1800 non-null   float64\n",
      " 11  SyndromeClass_2.0       1800 non-null   float64\n",
      " 12  SyndromeClass_3.0       1800 non-null   float64\n",
      " 13  SyndromeClass_4.0       1800 non-null   float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 197.0 KB\n"
     ]
    }
   ],
   "source": [
    "X_val.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m42\u001b[0m\n\u001b[1;33m    }\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################\n",
    "## Training various models\n",
    "\n",
    "# ## Each target column has a different wanted score (with it's params)\n",
    "# column_score_map = {'Virus' : (precision_score, {'average':'weighted'}), \n",
    "#     'Spreader': (recall_score, {'average': \"binary\", 'pos_label': \"Spreader\"}), \n",
    "#     'AtRisk': (recall_score, {'average': \"binary\", 'pos_label': \"atRisk\"})}\n",
    "\n",
    "## Each target column has a different wanted score (with it's params)\n",
    "column_score_map = {'Virus' : (accuracy_score, dict()), \n",
    "    'Spreader': (accuracy_score, dict()), \n",
    "    'AtRisk': (accuracy_score, dict())}\n",
    "\n",
    "## We use grid search to optimize our parameters\n",
    "def grid_search(model, X, y, param_grid, score_fn):\n",
    "    clf = GridSearchCV(estimator=model, param_grid=param_grid, scoring=score_fn,\n",
    "                    n_jobs=-1, verbose=4)\n",
    "    clf.fit(X, y)\n",
    "    return clf \n",
    "\n",
    "print('### Training ###')\n",
    "\n",
    "random_forest = (\n",
    "                'RandomForest', \n",
    "                RandomForestClassifier(), \n",
    "                {\n",
    "                    'max_depth': np.floor(np.linspace(10, 40, 20)).astype(int),\n",
    "                }\n",
    "            )\n",
    "\n",
    "ada_boost = (\n",
    "                'AdaBoost', \n",
    "                AdaBoostClassifier(), \n",
    "                {\n",
    "                    'learning_rate': [0.5],\n",
    "                    'n_estimators': np.floor(np.linspace(1, 20, 10)).astype(int),\n",
    "                    'base_estimator':  [DecisionTreeClassifier(max_depth=3,  min_samples_leaf=3)]\n",
    "                }\n",
    "            )\n",
    "\n",
    "gradient_boost = (\n",
    "                'GradientBoosting', \n",
    "                GradientBoostingClassifier(), \n",
    "                {\n",
    "                    \"min_samples_split\": [2],\n",
    "                    \"min_samples_leaf\": [1],\n",
    "                    \"max_depth\":[3],\n",
    "                    'n_estimators': np.floor(np.linspace(10, 100, 40)).astype(int)\n",
    "                }\n",
    "            )\n",
    "\n",
    "models = [\n",
    "#             ('SVC_rbf', svm.SVC(kernel='rbf'), dict(C=[0.1, 1, 10, 100, 1000], gamma=[0.0001, 0.001, 0.01, 0.1, 1])),\n",
    "#             ('KNN', KNeighborsClassifier(), dict(n_neighbors=np.linspace(2, 10, 9, dtype=int))),\n",
    "            random_forest,\n",
    "            # ('LogisticRegression', LogisticRegression(max_iter=1000), dict(C=[0.1, 1, 5, 7, 10])),\n",
    "            # ('PolynomialLogisticRegression',  Pipeline([('poly', PolynomialFeatures(degree=2)),\n",
    "#                                                         ('linear', LogisticRegression())]), dict()),\n",
    "            ada_boost,\n",
    "            gradient_boost]\n",
    "\n",
    "models_per_column = dict()\n",
    "\n",
    "for column in column_score_map:\n",
    "    print(f'# Fitting for column {column}')\n",
    "    fitted_models = []\n",
    "    for name, model, param_grid in models:\n",
    "        print(f'## Fitting model {name}')\n",
    "\n",
    "        score_fn, params = column_score_map[column]\n",
    "\n",
    "        clf = grid_search(model, X_train, y_train[column], param_grid, make_scorer(score_fn, **params))\n",
    "        fitted_models.append((name, clf))\n",
    "    models_per_column[column] = fitted_models\n",
    "\n",
    "\n",
    "# ## Each target column has a different wanted score (with it's params)\n",
    "# column_score_map = {'Virus' : (precision_score, {'average':'weighted'}), \n",
    "#     'Spreader': (recall_score, {'average': \"binary\", 'pos_label': \"Spreader\"}), \n",
    "#     'AtRisk': (recall_score, {'average': \"binary\", 'pos_label': \"atRisk\"})}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Checking column Virus\n",
      "## Checking model RandomForest\n",
      "# Checking column Spreader\n",
      "## Checking model RandomForest\n",
      "# Checking column AtRisk\n",
      "## Checking model RandomForest\n",
      "{'Virus': (RandomForestClassifier(max_depth=40), {'max_depth': 40}, 0.8161111111111111), 'Spreader': (RandomForestClassifier(max_depth=14), {'max_depth': 14}, 0.8594444444444445), 'AtRisk': (RandomForestClassifier(max_depth=10), {'max_depth': 10}, 0.8083333333333333)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################\n",
    "## Choose the best model for each task\n",
    "\n",
    "best_models = dict()\n",
    "\n",
    "for column in ['Virus', 'Spreader', 'AtRisk']:\n",
    "    print(f'# Checking column {column}')\n",
    "    fitted_models = models_per_column[column]\n",
    "    best_model, best_score = None, -1\n",
    "    for name, model in fitted_models:\n",
    "        print(f'## Checking model {name}')\n",
    "        y_hat = model.predict(X_val)\n",
    "        score_function, params = column_score_map[column]\n",
    "        score = score_function(y_val[column], y_hat, **params)\n",
    "        if score > best_score:\n",
    "            best_model, best_score = model, score\n",
    "    \n",
    "    best_models[column] = (best_model.best_estimator_, best_model.best_params_, best_score)\n",
    "\n",
    "print(best_models)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################\n",
    "## Predict on test data using chosen models\n",
    "\n",
    "df_test = pd.read_csv('Data/virus_hw5_test.csv')\n",
    "X_ret = pd.DataFrame(df_test['PatientID'], columns=['PatientID'])\n",
    "X_test = df_test.drop(labels=['PatientID'], axis=1)\n",
    "X_test = X_test[['DisciplineScore', 'TimeOnSocialActivities', 'AgeGroup', 'StepsPerYear', 'pcrResult4', 'pcrResult1',\n",
    "                   'pcrResult12', 'pcrResult5', 'pcrResult16', 'pcrResult14', 'SyndromeClass']]\n",
    "X_test = preprocessor.transform(X_test)\n",
    "X_ret['Virus'] = best_models['Virus'][0].predict(X_test)\n",
    "X_ret['Spreader'] = best_models['Spreader'][0].predict(X_test)\n",
    "X_ret['Risk'] = best_models['AtRisk'][0].predict(X_test)\n",
    "\n",
    "X_ret.to_csv('results/predicted.csv', index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (ml_hw2)",
   "language": "python",
   "name": "pycharm-64409fe0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
